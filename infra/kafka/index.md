# 개요
소셜 네트워크 사이트인 '링크드인' 에서는 파편화된 데이터 수집 및 분배 아키텍처를 운영하는 데에 어려움을 겪었다.
데이터를 생성하고 적재하기 위해서는 데이터를 생성하는 소스 App 과 데이터가 최종 적재되는 타겟 App 을 연결해야 한다.
초기 운영 시에는 단방향 통신을 통해 소스 -> 타겟 App 으로 연동하는 소스코드를 작성했고 아키텍처가 복잡하지 않았으므로 운영히 힘들지 않았다.
그러나 시간이 지날수록 아키텍처는 거대해졌고 데이터를 전송하는 라인이 기하급수적으로 복잡해지기 시작했다.

그러면서 하나의 App 에서 발생하는 장애가 전파되는 문제점 등이 발생했고
이를 해결하기 위해 링크드인 데이터팀에서는 기존에 나와 있던 각종 상용 데이터 프레임워크와 오픈소스를 아키텍처에 녹여내어 데이터 파이프라인의 파편화를 개선하려고 했다.
다양한 메시징 플랫폼과 ETL(Extract Transform Load) 툴을 적용하여 아키텍처를 변경하려고 노력했지만 파편화된 데이터 파이프라인의 복잡도를 낮춰주는 아키텍처가 되지는 못했다.

결국 링크드인의 데이터팀은 신규 시스템을 만들기로 결정했고 그 결과물이 아파치 카프카다.
링크드인의 내부 데이터 흐름을 개선하기 위해 개발한 카프카는 매우 훌륭하게 동작했다.
카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙집중화했다.

기존에 1:1 매칭으로 개발하고 운영하던 데이터 파이프라인은 커플링으로 인해 한쪽의 이슈가 다른 한쪽의 애플리케이션에 영향을 미치곤 했지만,
카프카는 이러한 의존도를 타파하였다.
이제 소스 애플리케이션에서 생성되는 데이터는 어느 타깃 애플리케이션으로 보낼 것인지 고민하지 않고 일단 카프카로 넣으면 된다.
카프카 내부에 데이터가 저장되는 파티션의 동작은 FIFO(First In First Out) 방식의 큐 자료구조와 유사하다.
큐에 데이터를 보내는 것이 '프로듀서' 이고 큐에서 데이터를 가져가는 것이 '컨슈머'다